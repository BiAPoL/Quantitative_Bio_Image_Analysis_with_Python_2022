
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Training a 2D Unet model &#8212; Quantitative Bio-image Analysis with Python</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Feature extraction" href="../day2f_feature_extraction/readme.html" />
    <link rel="prev" title="Stardist in Python: Training" href="02_Stardist2d_in_python_training.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/biapol_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Quantitative Bio-image Analysis with Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Quantitative Bio-Image Analysis using Python
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../day0/Readme.html">
   Course preparation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../day1/readme.html">
   Day 1: Introduction to Python and Bio-image Analysis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day1a_Python_Introduction/readme.html">
     Introduction to Python
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/01_our_first_juptyer_notebook.html">
       Python code in Jupyter notebooks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/02_Math_in_python.html">
       Basic math in python
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/03_Dont_try_this_at_home.html">
       Pitfalls when working with Jupyter notebooks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/04_Basic_types.html">
       Basic types in python
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/05_lists_tuples.html">
       Lists and tuples
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/05a_cropping_lists.html">
       Cropping lists
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/05b_sorting_lists.html">
       Sorting lists
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/05c_masking.html">
       Masking numpy arrays
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/06_Dictionaries_and_tables.html">
       Dictionaries
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/07_Conditions.html">
       Conditions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/08_loops.html">
       Loops
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1a_Python_Introduction/09_custom_functions.html">
       Functions
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../day1b_Introduction_Bio-image_Analysis/readme.html">
     Introduction to Bio-image Analysis
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day1w_Working_with_Images/readme.html">
     Opening and Displaying with Images in Python
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1w_Working_with_Images/01_Working_with_images.html">
       Working with images
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1w_Working_with_Images/02_Matplotlib_subplots_introduction.html">
       Subplots with matplotlib
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1w_Working_with_Images/03_Multi_channel_image_data.html">
       Multi-channel image data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1w_Working_with_Images/04_Image_file_formats.html">
       Image file formats
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day1x_Folder_Structures/readme.html">
     Folder Structures
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1x_Folder_Structures/05_Folder_structures.html">
       Folder Structures
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1x_Folder_Structures/06_Folder_structures2.html">
       Folder Structures
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day1y_Napari_Introduction/readme.html">
     napari from Jupyter notebooks
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1y_Napari_Introduction/07_Napari_from_Jupyter_introduction.html">
       Using Napari to visualize and interact with images
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1y_Napari_Introduction/08_my_segmentation_workflow_trailer.html">
       Segmentation Workflow Example with 3D Data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day1z_Image_Filters/readme.html">
     Image Filters
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1z_Image_Filters/09_Image_Filters.html">
       Image Filters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day1z_Image_Filters/10_Filters_in_3D_Isotropic_Data.html">
       3D Image Filters
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../day2/Readme.html">
   Day 2: Image Filtering, Segmentation and Feature Extraction
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day2a_background_subtraction/readme.html">
     Background subtraction
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2a_background_subtraction/01_Background_subtraction.html">
       Removing image noise
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day2b_image_segmentation/readme.html">
     Image segmentation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2b_image_segmentation/01_Thresholding.html">
       Thresholding
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2b_image_segmentation/03_Morphological_operations.html">
       Morphological Image Processing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2b_image_segmentation/04_Otsu_threshold.html">
       Otsu’s threshold method (optional)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day2c_instance_segmentation/readme.html">
     Instance Segmentation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2c_instance_segmentation/09_connected_component_labeling.html">
       Label images
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2c_instance_segmentation/10_touching_objects_labeling.html">
       Touching objects labeling
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2c_instance_segmentation/11_voronoi_tesselation.html">
       Voronoi tesselation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2c_instance_segmentation/11_voronoi_otsu_labeling.html">
       Voronoi-Otsu-labeling
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2c_instance_segmentation/12_Segmentation_3D.html">
       3D Image Segmentation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2c_instance_segmentation/14_segmentation_2d_membranes.html">
       Seeded watershed for membrane-based cell segmentation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2c_instance_segmentation/15_remove_labels_on_image_edges.html">
       Remove labels on image edges
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2c_instance_segmentation/16_open_close_labels.html">
       Label image refinement
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2c_instance_segmentation/19_the_segmentation_game.html">
       The Segmentation Game
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2c_instance_segmentation/20_Segmentation_quality_estimation.html">
       Image segmentation quality measurements
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day2d_machine_learning_apoc/readme.html">
     Machine learning for object segmentation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2d_machine_learning_apoc/01_supervised_machine_learning.html">
       Supervised machine learning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2d_machine_learning_apoc/02_exercise_apoc.html">
       Exercise: Interactive pixel and object classification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2d_machine_learning_apoc/04_demo_object_segmenter.html">
       Object segmentation on OpenCL-compatible GPUs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2d_machine_learning_apoc/05_train_on_folders.html">
       Training classifiers from folders of images
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="readme.html">
     Deep Learning for image segmentation
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="01_Stardist2d_in_python_getting_data.html">
       Stardist in Python: Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="02_Stardist2d_in_python_training.html">
       Stardist in Python: Training
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Training a 2D Unet model
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day2f_feature_extraction/readme.html">
     Feature extraction
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day2f_feature_extraction/01_Feature_extraction.html">
       Feature extraction
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../day3/Readme.html">
   Day 3: Biostatistics and data science
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day3a_Tabular_Data_and_Descriptive_Statistics/readme.html">
     Working with tabular data
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3a_Tabular_Data_and_Descriptive_Statistics/01_introduction_dataframes.html">
       Introduction to working with DataFrames
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3a_Tabular_Data_and_Descriptive_Statistics/02_basic_descriptive_statistics.html">
       Basic descriptive statistics
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3a_Tabular_Data_and_Descriptive_Statistics/03_descriptive_statistics_label_images.html">
       Descriptive statistics of labeled images
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3a_Tabular_Data_and_Descriptive_Statistics/04_append_tables.html">
       Appending tables
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3a_Tabular_Data_and_Descriptive_Statistics/05_handling_NaNs.html">
       Handling NaN values
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3a_Tabular_Data_and_Descriptive_Statistics/06_tidy_data.html">
       Tidy-Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3a_Tabular_Data_and_Descriptive_Statistics/07_split_apply_combine.html">
       Split-Apply-Combine
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day3b_Plotting/readme.html">
     Plotting Data with Seaborn
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
    <label for="toctree-checkbox-16">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3b_Plotting/01_Plotting_Data_with_Python.html">
       Plotting Data with Python
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3b_Plotting/02_Introduction_to_Seaborn.html">
       Introduction to Seaborn
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3b_Plotting/03_Plotting_distributions.html">
       Plotting Distributions with Seaborn
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3b_Plotting/04_Multivariate_views.html">
       Multivariate views
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day3c_statistics_and_tests/Readme.html">
     Statistics and tests
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3c_statistics_and_tests/01_Bland_altman_analysis.html">
       Method comparison and Bland-Altman Analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3c_statistics_and_tests/02_correlation.html">
       Correlation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3c_statistics_and_tests/03_correlation_matrix.html">
       Correlation matrix
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3c_statistics_and_tests/04_multiple_testing.html">
       Multiple testing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3c_statistics_and_tests/05_hypothesis_testing.html">
       Nonparametric testing
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day3e_dimensionality_reduction/Readme.html">
     Dimensionality reduction
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3e_dimensionality_reduction/01_UMAP.html">
       UMAP
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3e_dimensionality_reduction/02_UMAP.html">
       UMAP
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3e_dimensionality_reduction/03_PCA.html">
       PCA (Principle Component analysis)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day3f_clustering/Readme.html">
     Clustering
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3f_clustering/01_kmeans.html">
       K-means clustering
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3f_clustering/02_hdbscan.html">
       HDBSCAN
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day3f_clustering/03_interactive_dim_reduction_and_clustering.html">
       Interactive dimensioanlity reduction and clustering
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../day4/Readme.html">
   Day 4: Best practices in scientific programming and developing Napari plugins
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../day4a_Best_practices_scientific_programming/readme.html">
     Best practices in scientific programming
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day4b_writing_readable_code/readme.html">
     Writing readable code
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day4b_writing_readable_code/05_readable_code.html">
       Writing good code
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day4b_writing_readable_code/07_magic_numbers.html">
       Prevent magic numbers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day4b_writing_readable_code/08_divide_and_rule.html">
       Divide and rule
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day4b_writing_readable_code/09_custom_modules.html">
       Custom modules
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day4b_writing_readable_code/10_reading_exercise.html">
       Reading exercise
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day4b_writing_readable_code/11_exercise_modules.html">
       Exercise modularization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day4b_writing_readable_code/12_keep_it_short_and_simple.html">
       Keep it short and simple
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day4b_writing_readable_code/14_stackview.html">
       Interactive functions in Jupyter Lab
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day4c_crafting_napari_plugins/readme.html">
     Make your own napari plugin
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
    <label for="toctree-checkbox-22">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day4c_crafting_napari_plugins/01_creating_widgets_from_functions.html">
       Creating Widgets from Functions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day4c_crafting_napari_plugins/04_napari_cookiecutter.html">
       Creating a plugin from a template using the cookiecutter
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../day5/Readme.html">
   Day 5: Surfaces and bring your own data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../day5a_points_and_surfaces/Readme.html">
     Working with points and meshes
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../day5a_points_and_surfaces/01_creating_and_working_with_meshes.html">
       Working with surface data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../day5a_points_and_surfaces/02_advanced_surface_characteristics.html">
       Advanced surface characteristics
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../day5/Analyze_data_together.html">
     Work on your own data
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/BiAPoL/Quantitative_Bio_Image_Analysis_with_Python_2022/main?urlpath=tree/day2e_deep_learning_segmentation/02_2D_unet_training.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/BiAPoL/Quantitative_Bio_Image_Analysis_with_Python_2022"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/BiAPoL/Quantitative_Bio_Image_Analysis_with_Python_2022/issues/new?title=Issue%20on%20page%20%2Fday2e_deep_learning_segmentation/02_2D_unet_training.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/day2e_deep_learning_segmentation/02_2D_unet_training.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-preparation">
   Dataset preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#augmentation">
   Augmentation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-test-validation-split">
     Train/test/validation split
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-creation-and-preparation">
   Model creation and preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-loss">
   The loss
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#validation">
   Validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advanced-implementation-aspects">
   Advanced implementation aspects:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inference">
   Inference
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Training a 2D Unet model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-preparation">
   Dataset preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#augmentation">
   Augmentation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-test-validation-split">
     Train/test/validation split
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-creation-and-preparation">
   Model creation and preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-loss">
   The loss
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#validation">
   Validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advanced-implementation-aspects">
   Advanced implementation aspects:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inference">
   Inference
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="training-a-2d-unet-model">
<h1>Training a 2D Unet model<a class="headerlink" href="#training-a-2d-unet-model" title="Permalink to this headline">#</a></h1>
<p>In this model, we will demonstrate how to train a U-Net model from scratch. It is strongly encouraged to create a separate environment for this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">create</span> <span class="o">-</span><span class="n">n</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">segmentation</span> <span class="n">python</span><span class="o">=</span><span class="mf">3.9</span>
<span class="n">conda</span> <span class="n">activate</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">segmentation</span>
</pre></div>
</div>
<p>In order to correctly install pytorch, find the matching command for your system on the <a class="reference external" href="https://pytorch.org/get-started/locally/">pytorch page</a>:</p>
<p><img alt="" src="../_images/torch_get_started.png" /></p>
<p>After that is done, install some more packages:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mamba</span> <span class="n">install</span> <span class="n">scikit</span><span class="o">-</span><span class="n">image</span> <span class="n">albumentations</span> <span class="n">segmentation</span><span class="o">-</span><span class="n">models</span><span class="o">-</span><span class="n">pytorch</span> <span class="n">pandas</span> <span class="n">matplotlib</span> <span class="n">torchmetrics</span> <span class="n">tensorboard</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">yaml</span>

<span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="nn">albu</span>
<span class="kn">import</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">torchmetrics</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">CrossEntropyLoss</span>
<span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>

<span class="kn">import</span> <span class="nn">segmentation_models_pytorch</span> <span class="k">as</span> <span class="nn">smp</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\johamuel\Anaconda3\envs\pytorch-segmentation\lib\site-packages\tqdm\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div>
</div>
</div>
</div>
<section id="dataset-preparation">
<h2>Dataset preparation<a class="headerlink" href="#dataset-preparation" title="Permalink to this headline">#</a></h2>
<p>The first thing we have to do for Pytorch training, is tpo create a custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class for our dataset. This dataset object will then serve as a utility through which Pytorch can access and load all the data from the drive. During the training process we will iterate over our dataset, so the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> implementation needs to have two important member functions:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__len__()</span></code>: The Dataloader needs to know how <em>many</em> samples there are.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">__getitem__()</span></code>: The Dataloader needs to be able to access the i-th sample out of our whole dataset.</p></li>
</ul>
<p>In this example, we will create a pandas dataframe with two columns <code class="docutils literal notranslate"><span class="pre">image</span></code> and <code class="docutils literal notranslate"><span class="pre">mask</span></code> and pass this to the Dataset. Working with dataframes is particularly easy because it allows us to easily split our data into a training and a validation cohort.</p>
<p><em>Note 1</em>: We will add the option for augmentation to the datafly. If we pass an augmentation function as an argument (which should accept parameters <code class="docutils literal notranslate"><span class="pre">image</span></code> and <code class="docutils literal notranslate"><span class="pre">mask</span></code> as inputs), the augmentations are applied on-the-fly. We will use the <a class="reference external" href="https://albumentations.ai/">albumentations package</a> for this.
<em>Note 2</em>: We will use a pretrained model. Such pretrained models are typically implemented for “normal” images, i.e. RGB images. Hence, the used model expects images to have the dimensions <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">Y,</span> <span class="pre">X]</span></code>. Thus, if we work with grayscale images, we need to stack the single channel we are working with 3 times to create an artifical RGB image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Dataset</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">image_dir</span> <span class="o">=</span> <span class="s1">&#39;images&#39;</span><span class="p">,</span> <span class="n">labels_dir</span> <span class="o">=</span> <span class="s1">&#39;labels&#39;</span><span class="p">,</span> <span class="n">augmentation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">root</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">augmentation</span> <span class="o">=</span> <span class="n">augmentation</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">image_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">image_dir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">labels_dir</span><span class="p">)</span>
        
        <span class="n">images</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="n">image_dir</span><span class="p">))</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="n">labels_dir</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;images&#39;</span><span class="p">,</span> <span class="s1">&#39;labels&#39;</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">filename_image</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;images&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">filename_label</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">filename_image</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">filename_label</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmentation</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmentation</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
            <span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">]</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">image</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="s1">&#39;labels&#39;</span> <span class="p">:</span> <span class="n">mask</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]}</span>


    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Download the data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="s1">&#39;data.zip&#39;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;https://zenodo.org/record/7213527/files/HE_segmentation_data.zip&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data.zip&quot;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
        
<span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="s1">&#39;./data.zip&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s1">&#39;./data&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Unzip:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">root</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s1">&#39;./data&#39;</span><span class="p">)</span>
<span class="n">root</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;C:\\Users\\johamuel\\Documents\\BiAPoL\\Projects\\Quantitative_Bio_Image_Analysis_with_Python_2022\\docs\\day2e_deep_learning_segmentation\\data&#39;
</pre></div>
</div>
</div>
</div>
<p>Let’s use this opportunity to quickly check what the above-defined Dataset class does with this. For thhis, we create an instance of the Dataset class using the dataframe with the filenames of our training data. Then we’ll try to get an arbitrary sample from the dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MyDataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">))</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.image.AxesImage at 0x1ffbf048220&gt;
</pre></div>
</div>
<img alt="../_images/02_2D_unet_training_9_1.png" src="../_images/02_2D_unet_training_9_1.png" />
</div>
</div>
</section>
<section id="augmentation">
<h2>Augmentation<a class="headerlink" href="#augmentation" title="Permalink to this headline">#</a></h2>
<p>For a typical segmentation job, it makes sense to augment the data to a certain degree. Albumentations allows to compose several augmentations together and luckily apply it to the image and the mask alike on-the fly. We will use the following augmentations for the training:</p>
<ul class="simple">
<li><p>Vertical flip: Flip the image upside down in 50% of all calls</p></li>
<li><p>Horizontal flip: Same, but horizontal</p></li>
<li><p>Random Rotate: * Randomly rotate image and mask by 90 degrees in 50% of all calls</p></li>
<li><p>Random brightness/contrast: randomly change the brightness/contrast setting of the image in 20% of all calls</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">aug_train</span> <span class="o">=</span> <span class="n">albu</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">albu</span><span class="o">.</span><span class="n">VerticalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">albu</span><span class="o">.</span><span class="n">HorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">albu</span><span class="o">.</span><span class="n">RandomRotate90</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">albu</span><span class="o">.</span><span class="n">RandomBrightnessContrast</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<section id="train-test-validation-split">
<h3>Train/test/validation split<a class="headerlink" href="#train-test-validation-split" title="Permalink to this headline">#</a></h3>
<p>Last but not least, we need to create three subsets from our dataset, a training-, test- and validation-cohort. In every epoch of training (see below), the training process will look at all images in the training cohort and update our model based on this. The model is then applied to the images in the test cohort without updating the model. This is to see how well the method is currently performing. Finally, the model is appliedto the image data in the validation cohort to measure its performance on unknown data.  Scikit-learn provides the KFold strategy for problems like this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ds_train</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span> <span class="n">augmentation</span><span class="o">=</span><span class="n">aug_train</span><span class="p">)</span>
<span class="n">ds_test</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">))</span>
<span class="n">ds_valid</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Samples in training set: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ds_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Samples in testing set: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ds_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Samples in validation set: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ds_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Samples in training set:  503
Samples in testing set:  126
Samples in validation set:  70
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="model-creation-and-preparation">
<h2>Model creation and preparation<a class="headerlink" href="#model-creation-and-preparation" title="Permalink to this headline">#</a></h2>
<p>Next, we have to actually create an instance of a model which we will train for a number of epochs. This section will mostly set some parameters which are explained here.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">device</span></code>: GPU or CPU? torch works only on Cuda-capable cards. To enable GPU-training, set this variable to <code class="docutils literal notranslate"><span class="pre">cuda</span></code>. Otherwise set it to <code class="docutils literal notranslate"><span class="pre">cpu</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_classes</span></code>: As desribed elsewhere, we are only trying to separate a background nd a foreground here. Hence, there are only 2 classes in our case.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epochs</span></code>: In one epoch, the the Dataloader will go throough the entire dataset, update the layers and then check the net’s performance in the test dataset. This is then repeated <code class="docutils literal notranslate"><span class="pre">epochs</span></code> times</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: During the training process, multiple images are stitched together to a batch of images. This is done along a batch axis that is added to the image data. Typically, images are provided in  <code class="docutils literal notranslate"><span class="pre">[B,</span> <span class="pre">C,</span> <span class="pre">Y,</span> <span class="pre">X]</span></code> shape, with <code class="docutils literal notranslate"><span class="pre">B</span></code> being the batch dimension, <code class="docutils literal notranslate"><span class="pre">C</span></code> the channel dimension and <code class="docutils literal notranslate"><span class="pre">Y,</span> <span class="pre">X</span></code> being the actual image dimensions. If the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is set too large, the images may not fit on the GPU anymore.
<em>Note</em>: Images in a batch are usually batch-averaged! In other words, the pixel intensity values will be z-score normalized using the commmon mean and standard deviation of the entire batch. Making the batch too small can disrupt these running statistics.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>: How much the weights of every layer should be changed  in every training step. This is also referred to as the momentum of the training - see <a class="reference external" href="https://twitter.com/marktenenholtz/status/1490309316347248646">here</a> for a nice explanation!</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_workers</span></code>: How many CPU cores are allowed to be used to operate the dataloaders to feed the data to the network</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span>

<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">130</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">tile_size</span> <span class="o">=</span> <span class="n">ds_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># get from dataset</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">smp</span><span class="o">.</span><span class="n">Unet</span><span class="p">(</span>
    <span class="n">encoder_name</span><span class="o">=</span><span class="s1">&#39;resnet50&#39;</span><span class="p">,</span>
    <span class="n">encoder_weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span>
    <span class="n">classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unet(
  (encoder): ResNetEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (decoder): UnetDecoder(
    (center): Identity()
    (blocks): ModuleList(
      (0): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (1): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (2): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (3): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
      (4): DecoderBlock(
        (conv1): Conv2dReLU(
          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention1): Attention(
          (attention): Identity()
        )
        (conv2): Conv2dReLU(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (attention2): Attention(
          (attention): Identity()
        )
      )
    )
  )
  (segmentation_head): SegmentationHead(
    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): Identity()
    (2): Activation(
      (activation): Identity()
    )
  )
)
</pre></div>
</div>
</div>
</div>
<p>At the end of the day, deep learning is a tricky optimization job. torch provides a few optimizers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Specify optimizer &amp; early stopping</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span> <span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-loss">
<h2>The loss<a class="headerlink" href="#the-loss" title="Permalink to this headline">#</a></h2>
<p>An aspect of paramount importance is the used <strong>loss function</strong>. After all, deep learning is all about passing data through the network, evaluating the performance and then changing the weights accordingly. The loss function determines how exactlly performance is measured. Torch offers a few different implementations but you can basically implement any metric that compares two label images and calculates something like a degree of similarity. Something that is very commonly used (and thus being used here) is the <code class="docutils literal notranslate"><span class="pre">CrossEntropyLoss()</span></code> function, which calculates the cross-entropy of two label images. The <a class="reference external" href="https://en.wikipedia.org/wiki/Cross_entropy">CrossEntropy </a> is closely related to the <a class="reference external" href="https://en.wikipedia.org/wiki/Cross_entropy">Mutual Information</a>.</p>
<p>Since the cross-entropy is a bit abstract to interpret, we will use a more intuitive measure to monitor the performance of our network in the validation cohort: The <a class="reference external" href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard-coefficient</a>. During the training we should observe that the cross-entropy in the training process goes down while the Jaccard-index should converge closer to 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">criterion_train</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">criterion_test</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">accuracy</span>
</pre></div>
</div>
</div>
</div>
<section id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">#</a></h3>
<p>Now we have everything at hand to actually start training! For this, we first create Datasets from our train/test dataframes. Let’s not forget to pass the composed albumentations <strong>only to the training dataset.</strong> We could also apply the augmentations to the trainign data, but it is preferable to have performance statistics on the real, unchanged image data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create dataloaders</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">ds_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">ds_valid</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Every training epoch follows the following steps:</p>
<ul class="simple">
<li><p>Set the model to training mode: In this mode, torch automatically updates the gradients of the model’s layers on-the-fly as image data is passed through the layers. The optimizer can then have a look at these gradients to know how the convolutions in the respective layers need to be changed to improve performance</p></li>
<li><p>Reset the gradients known to the optimizer from the previous epoch</p></li>
<li><p>Pass each batch of training data through the network and calculate the loss (deviation of acquired result and correct mask)</p></li>
<li><p>Back-propagate the loss through the network and calculate the gradients</p></li>
<li><p>Let the optimizer update the weights of the network</p></li>
</ul>
<p>To check the progress of the training, navigate to the working directory in a terminal and open the tensorboard with</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=</span><span class="n">runs</span>
</pre></div>
</div>
<p>Then, navigate to <a class="reference external" href="http://localhost:6006/">http://localhost:6006/</a> in the browser.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_score</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># set to training mode</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># reset gradients</span>
    <span class="n">tk0</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Epoch: &#39;</span> <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">b_idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tk0</span><span class="p">):</span>
        
        <span class="c1"># Move images and masks in batch to GPU</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            
        <span class="c1"># Feed the batch through the network and catch output into a new dictionary key</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span>  <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">])</span>
        
        <span class="c1"># Calculate and track the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion_train</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
        <span class="n">avg_train_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        
        <span class="c1"># Update the weights</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;Loss/train&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">avg_train_loss</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">epoch</span><span class="p">)</span>
        
    <span class="c1"># Switch to validation: No updating gradients now.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">avg_test_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">tk1</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">b_idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tk1</span><span class="p">):</span>
            
            <span class="c1"># Move only images to GPU and directly pass the batch through the model</span>
            <span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="n">test_loss</span> <span class="o">=</span> <span class="n">criterion_test</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">int</span><span class="p">(),</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">avg_test_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)</span>
            
        <span class="n">averages</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">avg_test_loss</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>        
        <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loss/test class 0&#39;</span><span class="p">,</span> <span class="n">averages</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loss/test class 1&#39;</span><span class="p">,</span> <span class="n">averages</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loss/test class 2&#39;</span><span class="p">,</span> <span class="n">averages</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">epoch</span><span class="p">)</span>
        
    <span class="c1"># if this model is better than the ones before, save it</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">averages</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">averages</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;./best_model.pt&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train loss:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">avg_train_loss</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="s1">&#39;Test loss: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">averages</span><span class="p">))</span>
    
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="validation">
<h2>Validation<a class="headerlink" href="#validation" title="Permalink to this headline">#</a></h2>
<p>Last but not least, let’s apply the trained model to the data in the validation cohort and calculate performance statistics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">valid_score</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">tk2</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">))</span>

<span class="k">for</span> <span class="n">b_idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tk2</span><span class="p">):</span>
    <span class="c1"># Move only images to GPU and directly pass the batch through the model</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">criterion_test</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">int</span><span class="p">(),</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">valid_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">valid_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">valid_score</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">performance</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy for label </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">valid_score</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy for label 0: 0.9536442160606384
Accuracy for label 1: 0.8054279685020447
Accuracy for label 2: 0.9184861779212952
</pre></div>
</div>
</div>
</div>
</section>
<section id="advanced-implementation-aspects">
<h2>Advanced implementation aspects:<a class="headerlink" href="#advanced-implementation-aspects" title="Permalink to this headline">#</a></h2>
<p>There are a few options we can to improve the training process and make it more robust. Some of them are listed here and will be expored in more advanced notebooks for the sake of this notebook’s simplicity.</p>
<ul class="simple">
<li><p><strong>Early Stopping:</strong> We have implemented a naive way of stopping the training process if the model is good enough. However, to effectively prevent overfitting, we need to stop the training process as soon as performance is not improving anymore. Thus, a more suitable early stopping implementation would have to look at the train/test performance scores within the last X epochs and check if the variance of performance scores has been small. If so, the training process will be interrupted.</p></li>
<li><p><strong>Weighted sampling</strong>: If we want to segmented regions in the image, which are rare in our training data, any well-behaving network should lean towards not predicting such labels <em>at all</em>. After all, the error in prediction is small if these labels are sufficiently scarce. To counter this, we can introduce <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler">weighted sampling</a> to ensure that the network is equally exposed to all present labels in the image data.</p></li>
<li><p><strong>Scheduling</strong>: As the model converges closer to its optimum, it is not wise to keep updating the model at the same speed as during the first epochs. We can do this by changing the <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> parameter as we progress through the epochs. Thus, the steps become smaller and safer. See <a class="reference external" href="https://twitter.com/marktenenholtz/status/1490309316347248646">this tweet</a> for a nice visualization.</p></li>
<li><p><strong>Visualization</strong>: It is good practice to visualize the training process through a side-by-side comparison of reference annotation and predicted label image.</p></li>
</ul>
</section>
<section id="inference">
<h2>Inference<a class="headerlink" href="#inference" title="Permalink to this headline">#</a></h2>
<p>Applying the model to data is also called inference. Let’s try this on some sample data. If you have not trained a model of your own previously, you can load the one that comes with the downloaded data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;./data/best_model.pt&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;All keys matched successfully&gt;
</pre></div>
</div>
</div>
</div>
<p>Disable gradients:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;torch.autograd.grad_mode.no_grad at 0x1ffbf179280&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_image</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;./data/test_data.tif&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">test_image</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3, 2676, 3332)
</pre></div>
</div>
</div>
</div>
<p>We need to tile up our data because moving everything through the network at once takes too much memory:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tile_size</span><span class="o">=</span><span class="mi">512</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">tk0</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">b_idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tk0</span><span class="p">):</span>

        <span class="c1"># Move images and masks in batch to GPU</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="c1"># Feed the batch through the network and catch output into a new dictionary key</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span>  <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">40</span><span class="p">))</span>
            <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)))</span>
            <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Raw&#39;</span><span class="p">)</span>
            <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Background-ness&#39;</span><span class="p">)</span>
            <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Necrosis-ness&#39;</span><span class="p">)</span>
            <span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Vital-ness&#39;</span><span class="p">)</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 25%|██████████████████▌                                                       | 3/12 [00:06&lt;00:20,  2.26s/it]C:\Users\johamuel\AppData\Local\Temp\ipykernel_12704\602782010.py:13: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, axes = plt.subplots(ncols=4, figsize=(10,40))
100%|█████████████████████████████████████████████████████████████████████████| 12/12 [00:25&lt;00:00,  2.14s/it]
</pre></div>
</div>
<img alt="../_images/02_2D_unet_training_38_1.png" src="../_images/02_2D_unet_training_38_1.png" />
<img alt="../_images/02_2D_unet_training_38_2.png" src="../_images/02_2D_unet_training_38_2.png" />
<img alt="../_images/02_2D_unet_training_38_3.png" src="../_images/02_2D_unet_training_38_3.png" />
<img alt="../_images/02_2D_unet_training_38_4.png" src="../_images/02_2D_unet_training_38_4.png" />
<img alt="../_images/02_2D_unet_training_38_5.png" src="../_images/02_2D_unet_training_38_5.png" />
<img alt="../_images/02_2D_unet_training_38_6.png" src="../_images/02_2D_unet_training_38_6.png" />
<img alt="../_images/02_2D_unet_training_38_7.png" src="../_images/02_2D_unet_training_38_7.png" />
<img alt="../_images/02_2D_unet_training_38_8.png" src="../_images/02_2D_unet_training_38_8.png" />
<img alt="../_images/02_2D_unet_training_38_9.png" src="../_images/02_2D_unet_training_38_9.png" />
<img alt="../_images/02_2D_unet_training_38_10.png" src="../_images/02_2D_unet_training_38_10.png" />
<img alt="../_images/02_2D_unet_training_38_11.png" src="../_images/02_2D_unet_training_38_11.png" />
<img alt="../_images/02_2D_unet_training_38_12.png" src="../_images/02_2D_unet_training_38_12.png" />
<img alt="../_images/02_2D_unet_training_38_13.png" src="../_images/02_2D_unet_training_38_13.png" />
<img alt="../_images/02_2D_unet_training_38_14.png" src="../_images/02_2D_unet_training_38_14.png" />
<img alt="../_images/02_2D_unet_training_38_15.png" src="../_images/02_2D_unet_training_38_15.png" />
<img alt="../_images/02_2D_unet_training_38_16.png" src="../_images/02_2D_unet_training_38_16.png" />
<img alt="../_images/02_2D_unet_training_38_17.png" src="../_images/02_2D_unet_training_38_17.png" />
<img alt="../_images/02_2D_unet_training_38_18.png" src="../_images/02_2D_unet_training_38_18.png" />
<img alt="../_images/02_2D_unet_training_38_19.png" src="../_images/02_2D_unet_training_38_19.png" />
<img alt="../_images/02_2D_unet_training_38_20.png" src="../_images/02_2D_unet_training_38_20.png" />
<img alt="../_images/02_2D_unet_training_38_21.png" src="../_images/02_2D_unet_training_38_21.png" />
<img alt="../_images/02_2D_unet_training_38_22.png" src="../_images/02_2D_unet_training_38_22.png" />
<img alt="../_images/02_2D_unet_training_38_23.png" src="../_images/02_2D_unet_training_38_23.png" />
<img alt="../_images/02_2D_unet_training_38_24.png" src="../_images/02_2D_unet_training_38_24.png" />
<img alt="../_images/02_2D_unet_training_38_25.png" src="../_images/02_2D_unet_training_38_25.png" />
<img alt="../_images/02_2D_unet_training_38_26.png" src="../_images/02_2D_unet_training_38_26.png" />
<img alt="../_images/02_2D_unet_training_38_27.png" src="../_images/02_2D_unet_training_38_27.png" />
<img alt="../_images/02_2D_unet_training_38_28.png" src="../_images/02_2D_unet_training_38_28.png" />
<img alt="../_images/02_2D_unet_training_38_29.png" src="../_images/02_2D_unet_training_38_29.png" />
<img alt="../_images/02_2D_unet_training_38_30.png" src="../_images/02_2D_unet_training_38_30.png" />
<img alt="../_images/02_2D_unet_training_38_31.png" src="../_images/02_2D_unet_training_38_31.png" />
<img alt="../_images/02_2D_unet_training_38_32.png" src="../_images/02_2D_unet_training_38_32.png" />
<img alt="../_images/02_2D_unet_training_38_33.png" src="../_images/02_2D_unet_training_38_33.png" />
<img alt="../_images/02_2D_unet_training_38_34.png" src="../_images/02_2D_unet_training_38_34.png" />
<img alt="../_images/02_2D_unet_training_38_35.png" src="../_images/02_2D_unet_training_38_35.png" />
<img alt="../_images/02_2D_unet_training_38_36.png" src="../_images/02_2D_unet_training_38_36.png" />
<img alt="../_images/02_2D_unet_training_38_37.png" src="../_images/02_2D_unet_training_38_37.png" />
<img alt="../_images/02_2D_unet_training_38_38.png" src="../_images/02_2D_unet_training_38_38.png" />
<img alt="../_images/02_2D_unet_training_38_39.png" src="../_images/02_2D_unet_training_38_39.png" />
<img alt="../_images/02_2D_unet_training_38_40.png" src="../_images/02_2D_unet_training_38_40.png" />
<img alt="../_images/02_2D_unet_training_38_41.png" src="../_images/02_2D_unet_training_38_41.png" />
<img alt="../_images/02_2D_unet_training_38_42.png" src="../_images/02_2D_unet_training_38_42.png" />
<img alt="../_images/02_2D_unet_training_38_43.png" src="../_images/02_2D_unet_training_38_43.png" />
<img alt="../_images/02_2D_unet_training_38_44.png" src="../_images/02_2D_unet_training_38_44.png" />
<img alt="../_images/02_2D_unet_training_38_45.png" src="../_images/02_2D_unet_training_38_45.png" />
<img alt="../_images/02_2D_unet_training_38_46.png" src="../_images/02_2D_unet_training_38_46.png" />
<img alt="../_images/02_2D_unet_training_38_47.png" src="../_images/02_2D_unet_training_38_47.png" />
<img alt="../_images/02_2D_unet_training_38_48.png" src="../_images/02_2D_unet_training_38_48.png" />
<img alt="../_images/02_2D_unet_training_38_49.png" src="../_images/02_2D_unet_training_38_49.png" />
<img alt="../_images/02_2D_unet_training_38_50.png" src="../_images/02_2D_unet_training_38_50.png" />
<img alt="../_images/02_2D_unet_training_38_51.png" src="../_images/02_2D_unet_training_38_51.png" />
<img alt="../_images/02_2D_unet_training_38_52.png" src="../_images/02_2D_unet_training_38_52.png" />
<img alt="../_images/02_2D_unet_training_38_53.png" src="../_images/02_2D_unet_training_38_53.png" />
<img alt="../_images/02_2D_unet_training_38_54.png" src="../_images/02_2D_unet_training_38_54.png" />
<img alt="../_images/02_2D_unet_training_38_55.png" src="../_images/02_2D_unet_training_38_55.png" />
<img alt="../_images/02_2D_unet_training_38_56.png" src="../_images/02_2D_unet_training_38_56.png" />
<img alt="../_images/02_2D_unet_training_38_57.png" src="../_images/02_2D_unet_training_38_57.png" />
<img alt="../_images/02_2D_unet_training_38_58.png" src="../_images/02_2D_unet_training_38_58.png" />
<img alt="../_images/02_2D_unet_training_38_59.png" src="../_images/02_2D_unet_training_38_59.png" />
<img alt="../_images/02_2D_unet_training_38_60.png" src="../_images/02_2D_unet_training_38_60.png" />
<img alt="../_images/02_2D_unet_training_38_61.png" src="../_images/02_2D_unet_training_38_61.png" />
<img alt="../_images/02_2D_unet_training_38_62.png" src="../_images/02_2D_unet_training_38_62.png" />
<img alt="../_images/02_2D_unet_training_38_63.png" src="../_images/02_2D_unet_training_38_63.png" />
<img alt="../_images/02_2D_unet_training_38_64.png" src="../_images/02_2D_unet_training_38_64.png" />
<img alt="../_images/02_2D_unet_training_38_65.png" src="../_images/02_2D_unet_training_38_65.png" />
<img alt="../_images/02_2D_unet_training_38_66.png" src="../_images/02_2D_unet_training_38_66.png" />
<img alt="../_images/02_2D_unet_training_38_67.png" src="../_images/02_2D_unet_training_38_67.png" />
<img alt="../_images/02_2D_unet_training_38_68.png" src="../_images/02_2D_unet_training_38_68.png" />
<img alt="../_images/02_2D_unet_training_38_69.png" src="../_images/02_2D_unet_training_38_69.png" />
<img alt="../_images/02_2D_unet_training_38_70.png" src="../_images/02_2D_unet_training_38_70.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tk0</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([4, 3, 256, 256])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">model_children</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([4, 3, 256, 256])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ncols</span><span class="o">=</span><span class="mi">10</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="n">ncols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ncols</span><span class="p">):</span>
        <span class="n">feature_maps</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">batch</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">feature_maps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$N_</span><span class="si">{featuremaps}</span><span class="s1">$ &#39;</span><span class="o">+</span><span class="sa">f</span><span class="s1">&#39;= </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_maps</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">feature_maps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> x </span><span class="si">{</span><span class="n">feature_maps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;featuremaps.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/02_2D_unet_training_41_0.png" src="../_images/02_2D_unet_training_41_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">batch</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;input.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/02_2D_unet_training_42_0.png" src="../_images/02_2D_unet_training_42_0.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./day2e_deep_learning_segmentation"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="02_Stardist2d_in_python_training.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Stardist in Python: Training</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../day2f_feature_extraction/readme.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Feature extraction</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Marcelo Zoccoler, Johannes Müller, Till Korten, Robert Haase, DFG Cluster of Excellence "Physics of Life", TU Dresden<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>